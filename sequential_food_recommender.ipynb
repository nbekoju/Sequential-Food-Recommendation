{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer \n",
    "from recbole.utils import init_logger, init_seed, get_model, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model = \"GRU4Rec\", dataset=\"Food\", config_file_list=[\"config.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 May 14:03    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = Food_Dataset/Food\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niranjan/miniconda3/envs/recbole/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/niranjan/miniconda3/envs/recbole/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "30 May 14:03    INFO  Food\n",
      "The number of users: 226571\n",
      "Average actions of users: 4.997868208500684\n",
      "The number of items: 231638\n",
      "Average actions of items: 4.888541122532238\n",
      "The number of inters: 1132367\n",
      "The sparsity of the dataset: 99.99784238935331%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 May 14:04    INFO  [Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "30 May 14:04    INFO  [Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recbole.data.dataloader.general_dataloader.TrainDataLoader at 0x745ea563d400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size of interaction: 512\n",
      "    user_id, torch.Size([512]), cpu, torch.int64\n",
      "    item_id, torch.Size([512]), cpu, torch.int64\n",
      "    timestamp, torch.Size([512]), cpu, torch.float32\n",
      "    item_length, torch.Size([512]), cpu, torch.int64\n",
      "    item_id_list, torch.Size([512, 50]), cpu, torch.int64\n",
      "    timestamp_list, torch.Size([512, 50]), cpu, torch.float32\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GRU4Rec', <ModelType.SEQUENTIAL: 2>, device(type='cuda'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"model\"], config[\"MODEL_TYPE\"], config[\"device\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru4rec_model = get_model(config[\"model\"])\n",
    "model = gru4rec_model(config, train_data.dataset).to(config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 May 14:05    INFO  epoch 0 training [time: 57.88s, train loss: 18955.6827]\n",
      "30 May 14:05    INFO  epoch 0 evaluating [time: 1.32s, valid_score: 0.005900]\n",
      "30 May 14:05    INFO  valid result: \n",
      "recall@10 : 0.0177    mrr@10 : 0.0059    ndcg@10 : 0.0086    hit@10 : 0.0177    precision@10 : 0.0018\n",
      "30 May 14:05    INFO  Saving current: saved/GRU4Rec-May-30-2024_14-04-06.pth\n",
      "30 May 14:06    INFO  epoch 1 training [time: 58.00s, train loss: 18277.6918]\n",
      "30 May 14:06    INFO  epoch 1 evaluating [time: 1.30s, valid_score: 0.005800]\n",
      "30 May 14:06    INFO  valid result: \n",
      "recall@10 : 0.0173    mrr@10 : 0.0058    ndcg@10 : 0.0084    hit@10 : 0.0173    precision@10 : 0.0017\n",
      "30 May 14:07    INFO  epoch 2 training [time: 58.05s, train loss: 17832.3166]\n",
      "30 May 14:07    INFO  epoch 2 evaluating [time: 1.31s, valid_score: 0.006300]\n",
      "30 May 14:07    INFO  valid result: \n",
      "recall@10 : 0.0192    mrr@10 : 0.0063    ndcg@10 : 0.0093    hit@10 : 0.0192    precision@10 : 0.0019\n",
      "30 May 14:07    INFO  Saving current: saved/GRU4Rec-May-30-2024_14-04-06.pth\n",
      "30 May 14:08    INFO  epoch 3 training [time: 58.08s, train loss: 17306.9265]\n",
      "30 May 14:08    INFO  epoch 3 evaluating [time: 1.30s, valid_score: 0.006500]\n",
      "30 May 14:08    INFO  valid result: \n",
      "recall@10 : 0.0187    mrr@10 : 0.0065    ndcg@10 : 0.0093    hit@10 : 0.0187    precision@10 : 0.0019\n",
      "30 May 14:08    INFO  Saving current: saved/GRU4Rec-May-30-2024_14-04-06.pth\n",
      "30 May 14:09    INFO  epoch 4 training [time: 58.07s, train loss: 16744.0113]\n",
      "30 May 14:09    INFO  epoch 4 evaluating [time: 1.30s, valid_score: 0.006600]\n",
      "30 May 14:09    INFO  valid result: \n",
      "recall@10 : 0.018    mrr@10 : 0.0066    ndcg@10 : 0.0092    hit@10 : 0.018    precision@10 : 0.0018\n",
      "30 May 14:09    INFO  Saving current: saved/GRU4Rec-May-30-2024_14-04-06.pth\n",
      "30 May 14:10    INFO  epoch 5 training [time: 58.09s, train loss: 16166.7300]\n",
      "30 May 14:10    INFO  epoch 5 evaluating [time: 1.30s, valid_score: 0.006100]\n",
      "30 May 14:10    INFO  valid result: \n",
      "recall@10 : 0.0174    mrr@10 : 0.0061    ndcg@10 : 0.0087    hit@10 : 0.0174    precision@10 : 0.0017\n",
      "30 May 14:11    INFO  epoch 6 training [time: 58.06s, train loss: 15577.7833]\n",
      "30 May 14:11    INFO  epoch 6 evaluating [time: 1.30s, valid_score: 0.005400]\n",
      "30 May 14:11    INFO  valid result: \n",
      "recall@10 : 0.0157    mrr@10 : 0.0054    ndcg@10 : 0.0077    hit@10 : 0.0157    precision@10 : 0.0016\n",
      "30 May 14:12    INFO  epoch 7 training [time: 58.06s, train loss: 14989.2234]\n",
      "30 May 14:12    INFO  epoch 7 evaluating [time: 1.30s, valid_score: 0.006100]\n",
      "30 May 14:12    INFO  valid result: \n",
      "recall@10 : 0.016    mrr@10 : 0.0061    ndcg@10 : 0.0084    hit@10 : 0.016    precision@10 : 0.0016\n",
      "30 May 14:13    INFO  epoch 8 training [time: 58.02s, train loss: 14405.4748]\n",
      "30 May 14:13    INFO  epoch 8 evaluating [time: 1.30s, valid_score: 0.005700]\n",
      "30 May 14:13    INFO  valid result: \n",
      "recall@10 : 0.0147    mrr@10 : 0.0057    ndcg@10 : 0.0078    hit@10 : 0.0147    precision@10 : 0.0015\n",
      "30 May 14:14    INFO  epoch 9 training [time: 58.01s, train loss: 13833.9779]\n",
      "30 May 14:14    INFO  epoch 9 evaluating [time: 1.30s, valid_score: 0.004700]\n",
      "30 May 14:14    INFO  valid result: \n",
      "recall@10 : 0.0129    mrr@10 : 0.0047    ndcg@10 : 0.0066    hit@10 : 0.0129    precision@10 : 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066 OrderedDict([('recall@10', 0.018), ('mrr@10', 0.0066), ('ndcg@10', 0.0092), ('hit@10', 0.018), ('precision@10', 0.0018)])\n"
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0066 OrderedDict([('recall@10', 0.018), ('mrr@10', 0.0066), ('ndcg@10', 0.0092), ('hit@10', 0.018), ('precision@10', 0.0018)])\n"
     ]
    }
   ],
   "source": [
    "print(best_valid_score, best_valid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 May 15:05    INFO  Loading model structure and parameters from saved/GRU4Rec-May-30-2024_14-04-06.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.0191), ('mrr@10', 0.0074), ('ndcg@10', 0.0101), ('hit@10', 0.0191), ('precision@10', 0.0019)])\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)\n",
    "\n",
    "# When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "trainer.eval_collector.data_collect(train_data)\n",
    "\n",
    "checkpoint_file = \"saved/GRU4Rec-May-30-2024_14-04-06.pth\"\n",
    "test_result = trainer.evaluate(test_data, model_file=checkpoint_file)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
